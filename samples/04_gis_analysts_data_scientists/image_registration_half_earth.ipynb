{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration of Scanned Maps and Species Hotspots onto World Map for Half Earth Project Using Computer Vision\n",
    "The sample code uses Computer Vision techniques to automatically register scanned images of any part of the world onto the world map and hence overlay the species hotspots depicted in the scanned images onto the world map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "OpenCV library: This sample requires installation of OpenCV library. Kindly install OpenCV using the following command:\n",
    "pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Used\n",
    "The data used for this sample are the scanned images from Half Earth Project and the corresponding species region masks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder where the scanned map images are placed\n",
    "IMAGES_TO_REGISTER_FOLDER = r\"C:\\Users\\ati11038\\Documents\\workspace\\data\" \\\n",
    "                            r\"\\half_earth\\extracted_samples\\extracted_maps\"\n",
    "\n",
    "# Path to the folder where the species region mask images are placed\n",
    "IMAGES_TO_REGISTER_SPECIES_MASKS_FOLDER = r\"C:\\Users\\ati11038\\Documents\" \\\n",
    "                                         r\"\\workspace\\data\\half_earth\\extracted_samples\" \\\n",
    "                                          r\"\\extracted_masks\"\n",
    "\n",
    "# File path and filename of world image file \n",
    "WORLD_MAP_IMAGE_PATH = r\"C:\\Users\\ati11038\\Documents\\workspace\\data\\half_earth\\world_map\"\n",
    "WORLD_MAP_IMAGE_NAME = \"map_without_rivers.tif\"\n",
    "\n",
    "# Path to the folder where the outputs need to appear\n",
    "RESULTS_FOLDER = r\"C:\\\\Users\\\\ati11038\\\\Documents\\\\workspace\\\\data\\\\half_earth\\\\results\\\\main\" \\\n",
    "                 r\"\\\\23_4_2020\\\\3\"\n",
    "\n",
    "# Minimum expected IOU of homography transform result with reference homography\n",
    "# to qualify as improved homography\n",
    "# (float: 0.0 - 1.0)\n",
    "IOU_THRESHOLD_HOMOGRAPHY = 0.85\n",
    "\n",
    "# Minimum expected spread of estimated control points over the scanned image\n",
    "# (float: 0.0 - 1.0)\n",
    "CONTOUR_RECT_AREA_RATIO_THRESHOLD = 0.40\n",
    "\n",
    "# Division factor w.r.t diagonal of template for estimating size of contour patch\n",
    "# (int: 8 - 12)\n",
    "CONTOUR_PATCH_SIZE_FACTOR = 8\n",
    "\n",
    "# Maximum allowed non zero pixels in contour patch to be selected for matching\n",
    "# (float: 0.0 - 1.0)\n",
    "CONTOUR_PATCH_NON_ZERO_THRESHOLD = 0.6\n",
    "\n",
    "# Maximum allowed non zero pixels in world map patch to be selected for matching\n",
    "# (float: 0.0 - 1.0)\n",
    "WORLD_MAP_PATCH_NON_ZERO_THRESHOLD = 0.6\n",
    "\n",
    "# Multiplication factor w.r.t contour patch for estimating size of world map patch\n",
    "# (float: 1.0 - 5.0)\n",
    "WORLD_MAP_PATCH_SIZE_FACTOR = 2.5\n",
    "\n",
    "# Maximum allowed distance of control points from the nearest contour point\n",
    "# for control point refinement\n",
    "# (int: 1 - 10) \n",
    "REFINEMENT_DISTANCE_THRESHOLD = 5\n",
    "\n",
    "# Minimum threshold for segmenting mask from species region mask image\n",
    "# (int: 1 - 255)\n",
    "SPECIES_REGION_MASK_THRESHOLD = 50\n",
    "SPECIES_REGION_MASK_VALUE = 255\n",
    "\n",
    "# Upper and lower thresholds for homogenizing query image\n",
    "HOMOGENIZE_UPPER_THRESHOLD = 245\n",
    "\n",
    "# Boundary values for latitude and longitude corresponding to world map image\n",
    "LONGITUDE_EXTREME_LEFT = -180\n",
    "LATITUDE_EXTREME_TOP = 85\n",
    "LONGITUDE_EXTREME_RIGHT = 180\n",
    "LATITUDE_EXTREME_BOTTOM = -85\n",
    "\n",
    "# Maximum number of control points needed \n",
    "MAX_CONTROL_POINTS = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#world_map_img = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_image_prefix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#degree_per_pixel_x = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#degree_per_pixel_y = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def find_current_timestamp():\n",
    "    \"\"\"\n",
    "    Creates a string representing the current timestamp\n",
    "\n",
    "    :returns: \n",
    "        timestamp_str: Current timestamp string in the format \"%H_%M_%S_%f\"\n",
    "    \"\"\"\n",
    "\n",
    "    datetime_obj = datetime.now()\n",
    "    timestamp_str = datetime_obj.strftime(\"%H_%M_%S_%f\")\n",
    "    return timestamp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_image_to_disk(image_to_write, image_suffix):\n",
    "    \"\"\"\n",
    "    Saves image to disk\n",
    "\n",
    "    :param image_to_write: Image which needs to be written to disk\n",
    "    :param image_suffix: Suffix for the image name to be formed\n",
    "    \n",
    "    :returns: \n",
    "        None\n",
    "    \"\"\"\n",
    "    image_dir = RESULTS_FOLDER + \"\\\\\" + current_image_prefix\n",
    "    \n",
    "    # Create directory if it does not exist\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "    \n",
    "    image_name = current_image_prefix + \"_\" + image_suffix\n",
    "    image_path =  image_dir + \"\\\\\" + find_current_timestamp()\\\n",
    "                  + \"_\" + image_name + \".jpg\"\n",
    "    \n",
    "    cv2.imwrite(image_path, image_to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_img, kernel_size):\n",
    "    \"\"\"\n",
    "    Create a binary mask and get rid of features such as rivers, discontinuities\n",
    "\n",
    "    :param input_img: Input image to be registered on the world map\n",
    "    :param kernel_size: Kernel size for morphological operation\n",
    "\n",
    "    :return\n",
    "        preprocessed_img: Image without features such as rivers, discontinuities\n",
    "    \"\"\"\n",
    "    \n",
    "    input_img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    input_height = input_img_gray.shape[0]\n",
    "    input_width = input_img_gray.shape[1]\n",
    "\n",
    "    binary_mask = np.zeros((input_height, input_width),\n",
    "                           dtype=np.uint8)\n",
    "\n",
    "    for y in range(0, input_height):\n",
    "        for x in range(0, input_width):\n",
    "            if input_img_gray[y][x] > HOMOGENIZE_UPPER_THRESHOLD:\n",
    "                binary_mask[y][x] = 255\n",
    "\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "\n",
    "    binary_mask_closed = cv2.morphologyEx(binary_mask,\n",
    "                                          cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    binary_mask_closed_eroded = cv2.erode(binary_mask_closed,\n",
    "                                          kernel, iterations=1)\n",
    "    \n",
    "    preprocessed_img = np.zeros((input_height, input_width),\n",
    "                                dtype=np.uint8)\n",
    "\n",
    "    for y in range(0, input_height):\n",
    "        for x in range(0, input_width):\n",
    "            if binary_mask_closed_eroded[y][x] == 255:\n",
    "                preprocessed_img[y][x] = 255\n",
    "            else:\n",
    "                #modified_input_img[y][x] = input_img[y][x]\n",
    "                preprocessed_img[y][x] = 0\n",
    "                \n",
    "    return preprocessed_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homogenize(input_img):\n",
    "    \"\"\"\n",
    "    Converts color image to binary image with landmass depicted in white and\n",
    "    other regions depicted in black, also filling the species region pixels\n",
    "\n",
    "    :param input_img: Input image to be homogenized\n",
    "\n",
    "    :returns:\n",
    "        homogenized_img: Homogenized Image\n",
    "    \"\"\"\n",
    "\n",
    "    if input_img.ndim != 2:\n",
    "        input_img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        input_img_gray = input_img\n",
    "\n",
    "    homogenized_img = np.zeros((input_img_gray.shape[0],\n",
    "                                input_img_gray.shape[1]), dtype=np.uint8)\n",
    "\n",
    "    input_img_height = input_img_gray.shape[0]\n",
    "    input_img_width = input_img_gray.shape[1]\n",
    "\n",
    "    for y in range(0, input_img_height):\n",
    "        for x in range(0, input_img_width):\n",
    "            if input_img_gray[y][x] >= HOMOGENIZE_UPPER_THRESHOLD:\n",
    "                homogenized_img[y][x] = 255\n",
    "            else:\n",
    "                homogenized_img[y][x] = 0\n",
    "\n",
    "    return homogenized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_region_mask(mask_img):\n",
    "    \"\"\"\n",
    "    Create binary mask for species region using the original color species region image\n",
    "\n",
    "    :param mask_img: Color image of species mask\n",
    "    \n",
    "    :returns: \n",
    "        mask_img: Mask representing species region\n",
    "    \"\"\"\n",
    "\n",
    "    mask_img_gray = cv2.cvtColor(mask_img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask_img = cv2.threshold(mask_img_gray,\n",
    "                                  SPECIES_REGION_MASK_THRESHOLD,\n",
    "                                  SPECIES_REGION_MASK_VALUE,\n",
    "                                  cv2.THRESH_BINARY)\n",
    "    \n",
    "    return mask_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_mask_pixels(input_img, mask):\n",
    "    \"\"\"\n",
    "    Fills the mask pixels of image with white\n",
    "\n",
    "    :param input_img: Color map image with species region\n",
    "    :param mask: Binary mask image of species region\n",
    "    \n",
    "    :returns: \n",
    "        input_img_copy: Filled color image\n",
    "    \"\"\"\n",
    "\n",
    "    input_img_copy = input_img.copy()\n",
    "\n",
    "    mask_height = mask.shape[0]\n",
    "    mask_width = mask.shape[1]\n",
    "\n",
    "    for y in range(0, mask_height):\n",
    "        for x in range(0, mask_width):\n",
    "            if mask[y][x] == 255:\n",
    "                input_img_copy[y][x][0] = 255\n",
    "                input_img_copy[y][x][1] = 255\n",
    "                input_img_copy[y][x][2] = 255\n",
    "\n",
    "    return input_img_copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining computation helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(point1_x, point1_y, point2_x, point2_y):\n",
    "    \"\"\"\n",
    "    Find distance between two points\n",
    "    point1_x: x coordinate of first point\n",
    "    point1_y: y coordinate of first point\n",
    "    point2_x: x coordinate of second point\n",
    "    point2_y: y coordinate of second point\n",
    "\n",
    "    :returns:\n",
    "        distance: Euclidean distance between two points\n",
    "    \"\"\"\n",
    "\n",
    "    distance = math.sqrt((point1_x - point2_x) ** 2 \n",
    "                         + (point1_y - point2_y) ** 2)\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diagonal_length(length, height):\n",
    "    \"\"\"\n",
    "    Find the length of diagonal of a rectangle\n",
    "\n",
    "    :param length: Length of rectangle\n",
    "    :param height: Height of rectangle\n",
    "\n",
    "    :returns:\n",
    "        length_diag: Length of the diagonal\n",
    "    \"\"\"\n",
    "\n",
    "    length_diag = math.sqrt((length)** 2 + (height)** 2)\n",
    "\n",
    "    return length_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_offset_to_points(input_contour, offset_x, offset_y):\n",
    "    \"\"\"\n",
    "    Add offset to points on contour\n",
    "\n",
    "    :param input_contour: Contour which needs to be processed\n",
    "    :param offset_x: Offset which needs to be added in x co-ordinate\n",
    "    :param offset_y: Offset which needs to be added in y co-ordinate\n",
    "\n",
    "    :returns: \n",
    "        input_contour: Contour with offsetted points\n",
    "    \"\"\"\n",
    "\n",
    "    for point in input_contour:\n",
    "        point[0][0] += offset_x\n",
    "        point[0][1] += offset_y\n",
    "\n",
    "    return input_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nonzero_ratio(input_img):\n",
    "    \"\"\"\n",
    "    Calculates the ratio of non zero pixels area w.r.t entire area of image\n",
    "    \n",
    "    :param: input_img: Image for which ratio needs to be computed\n",
    "    \n",
    "    :returns:\n",
    "        ratio: Non-zero area ratio\n",
    "    \"\"\"\n",
    "    \n",
    "    non_zero_area = cv2.countNonZero(input_img)\n",
    "    total_area = input_img.shape[0] * input_img.shape[1]\n",
    "\n",
    "    ratio = non_zero_area / total_area\n",
    "\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_ratios(bb_start_x, bb_start_y, bb_end_x, bb_end_y, point_x, point_y):\n",
    "    \"\"\"\n",
    "    Calculates ratios of distances for X and Y from starting and ending co-ordinate of \n",
    "    X and Y respectively.\n",
    "    \n",
    "    :param: bb_start_x: X co-ordinate of left top corner of bounding box\n",
    "    :param: bb_start_y: Y co-ordinate of left top corner of bounding box\n",
    "    :param: bb_end_x: X co-ordinate of right bottom corner of bounding box\n",
    "    :param: bb_end_y: Y co-ordinate of right bottom corner of bounding box\n",
    "    :param: point_x: X co-ordinate of the point for which ratios need to be computed\n",
    "    :param: point_y: Y co-ordinate of the point for which ratios need to be computed\n",
    "    \n",
    "    :returns:\n",
    "        ratio_x: Ratio of distance of x co-ordinate of point from starting and ending\n",
    "                 x co-ordinates of bounding box\n",
    "        ratio_y: Ratio of distance of y co-ordinate of point from starting and ending\n",
    "                 y co-ordinates of bounding box\n",
    "    \"\"\"\n",
    "\n",
    "    # For numerical stability\n",
    "    epsilon = 0.00001\n",
    "        \n",
    "    distance_point_x_start_x = point_x - bb_start_x\n",
    "    distance_point_x_end_x = bb_end_x - point_x\n",
    "\n",
    "    distance_point_y_start_y = point_y - bb_start_y\n",
    "    distance_point_y_end_y = bb_end_y - point_y\n",
    "\n",
    "    ratio_x = (distance_point_x_start_x / (distance_point_x_end_x + epsilon))\n",
    "\n",
    "    ratio_y = (distance_point_y_start_y / (distance_point_y_end_y + epsilon))\n",
    "    \n",
    "    return ratio_x, ratio_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bb_boundary(bb_start_x, bb_start_y, bb_end_x, bb_end_y, height, width):\n",
    "    \"\"\"\n",
    "    Checks the boundary and modifies the values if necessary\n",
    "    \n",
    "    :param: bb_start_x: X co-ordinate of left top corner of bounding box\n",
    "    :param: bb_start_y: Y co-ordinate of left top corner of bounding box\n",
    "    :param: bb_end_x: X co-ordinate of right bottom corner of bounding box\n",
    "    :param: bb_end_y: Y co-ordinate of right bottom corner of bounding box\n",
    "    :param: height: Height of the image\n",
    "    :param: width: Width of the image\n",
    "    \n",
    "    :returns:\n",
    "        bb_start_x: Modified X co-ordinate of left top corner of bounding box\n",
    "        bb_start_y: Modified Y co-ordinate of left top corner of bounding box\n",
    "        bb_end_x: Modified X co-ordinate of right bottom corner of bounding box\n",
    "        bb_end_y: Modified Y co-ordinate of right bottom corner of bounding box\n",
    "    \"\"\"\n",
    "    if bb_start_x < 0:\n",
    "        bb_start_x = 0\n",
    "   \n",
    "    if bb_start_y < 0:\n",
    "        bb_start_y = 0\n",
    "\n",
    "    if bb_end_x >= width:\n",
    "        bb_end_x = width - 1\n",
    "\n",
    "    if bb_end_y >= height:\n",
    "        bb_end_y = height - 1\n",
    "\n",
    "    return bb_start_x, bb_start_y, bb_end_x, bb_end_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_color_list(size):\n",
    "    \"\"\"\n",
    "    Generate a list of specified size with random color values\n",
    "\n",
    "    :param size: Size of the list which needs to be returned\n",
    "\n",
    "    :returns:\n",
    "       color_list: List of random color values\n",
    "    \"\"\"\n",
    "\n",
    "    color_list = []\n",
    "\n",
    "    for i in range(0, size):\n",
    "        color_tuple = tuple(np.random.choice(range(256), size=3))\n",
    "        color_tuple = tuple([int(x) for x in color_tuple])\n",
    "        color_list.append(color_tuple)\n",
    "\n",
    "    return color_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou_binary_images(image1, image2):\n",
    "    \"\"\"\n",
    "    Calculate iou using two binary images\n",
    "\n",
    "    :param image1: First binary image\n",
    "    :param image2: Second binary image\n",
    "\n",
    "    :returns:\n",
    "        iou(float): Computed IOU value \n",
    "    \"\"\"\n",
    "\n",
    "    intersection_img = cv2.bitwise_and(image1, image2)\n",
    "    intersection_pixels = cv2.countNonZero(intersection_img)\n",
    "\n",
    "    union_img = cv2.bitwise_or(image1, image2)\n",
    "    union_pixels = cv2.countNonZero(union_img)\n",
    "\n",
    "    iou = intersection_pixels / union_pixels\n",
    "\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining core algorithm functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_contours(input_img):\n",
    "    \"\"\"\n",
    "    Detects contours in the input image\n",
    "    \n",
    "    :param input_img : Input image for which contours need to be computed\n",
    "    \n",
    "    :returns:\n",
    "        contours : List of computed contours for the input image\n",
    "    \"\"\"\n",
    "    if input_img.ndim != 2:\n",
    "        input_img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        input_img_gray = input_img\n",
    "\n",
    "    ret, input_img_gray_thresh = cv2.threshold(input_img_gray, 127, 255, 0)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(input_img_gray_thresh,\n",
    "                                           cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_template(template, search_img, start_scale, end_scale, num_scales):\n",
    "    \"\"\"\n",
    "    Performs template matching to locate the template in the world map\n",
    "\n",
    "    :param template: Template image which needs to be registered on the world map\n",
    "    :param search_img: Image in which template needs to be searched\n",
    "    :param start_scale: Starting value of scale interval\n",
    "    :param end_scale: Ending value of scale interval\n",
    "    :param num_scales: Number of scales within the scale interval\n",
    "\n",
    "    :returns:\n",
    "        start_x: Starting X co-ordinate of detected bounding box\n",
    "        start_y: Starting Y co-ordinate of detected bounding box\n",
    "        end_x: Ending X co-ordinate of detected bounding box\n",
    "        end_y: Ending Y co-ordinate of detected bounding box\n",
    "        max_val: Value of template match score for the detected bounding box\n",
    "        scale_factor: Scale at which the match was found for the template\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    template_height = template.shape[0]\n",
    "    template_width = template.shape[1]\n",
    "\n",
    "    start_x = 0\n",
    "    start_y = 0\n",
    "    end_x = 0\n",
    "    end_y = 0\n",
    "    max_val = -1\n",
    "\n",
    "    found = None\n",
    "    # match_map_img = None\n",
    "\n",
    "    # loop over the scales of the image\n",
    "    for scale in np.linspace(start_scale, end_scale, num_scales)[::-1]:\n",
    "        # resize the image according to the scale, and keep track\n",
    "        # of the ratio of the resizing\n",
    "        resized = imutils.resize(search_img,\n",
    "                                 width=int(search_img.shape[1] * scale))\n",
    "\n",
    "        scale_factor = search_img.shape[1] / float(resized.shape[1])\n",
    "\n",
    "        # If the resized image is smaller than the template, then break\n",
    "        # from the loop\n",
    "        if resized.shape[0] < template_height or resized.shape[1] < template_width:\n",
    "            break\n",
    "\n",
    "        # Match the template in the resized image and store the result image\n",
    "        result = cv2.matchTemplate(resized, template, cv2.TM_CCOEFF)\n",
    "\n",
    "        # Find the maximum template match score and location in the result image\n",
    "        (_, max_val, _, max_loc) = cv2.minMaxLoc(result)\n",
    "\n",
    "        # If there is a new maximum correlation value, then update\n",
    "        # the bookkeeping variable\n",
    "        if found is None or max_val > found[0]:\n",
    "            found = (max_val, max_loc, scale_factor)\n",
    "            # match_map_img = result\n",
    "\n",
    "    # Check if we have found a match\n",
    "    if found is not None:\n",
    "\n",
    "        # Unpack the bookkeeping variable and compute the (x, y) coordinates\n",
    "        # of the bounding box based on the resized ratio\n",
    "        (max_val, max_loc, scale_factor) = found\n",
    "        (start_x, start_y) = (int(max_loc[0] * scale_factor), int(max_loc[1] * scale_factor))\n",
    "        (end_x, end_y) = (int((max_loc[0] + template_width) * scale_factor),\n",
    "                          int((max_loc[1] + template_height) * scale_factor))\n",
    "    else:\n",
    "        max_val = -1\n",
    "\n",
    "    return start_x, start_y, end_x, end_y, max_val, scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_contour_point(input_contour, pt_x, pt_y):\n",
    "    \"\"\"\n",
    "    Find point on contour which is nearest to the given point\n",
    "    \n",
    "    :param input_contour: Contour on which points needs to be evaluated for nearness\n",
    "    :param pt_x: X co-ordinate of point\n",
    "    :param pt_y: Y co-ordinate of point\n",
    "    \n",
    "    :returns:\n",
    "        min_x: X co-ordinate of contour point nearest to input point\n",
    "        min_y: Y co-ordinate of contour point nearest to input point\n",
    "        min_index: Index of contour point nearest to input point\n",
    "        min_distance: Distance of contour point nearest to input point\n",
    "    \"\"\"\n",
    "\n",
    "    distance = cv2.pointPolygonTest(contour, (pt_x, pt_y), True)\n",
    "\n",
    "    min_distance = float(\"inf\")\n",
    "    min_index = -1\n",
    "    min_x = -1\n",
    "    min_y = -1\n",
    "\n",
    "    for i, contour_pt in enumerate(contour):\n",
    "        distance = find_distance(contour_pt[0][0], contour_pt[0][1], pt_x, pt_y)\n",
    "\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            min_index = i\n",
    "            min_x = contour_pt[0][0]\n",
    "            min_y = contour_pt[0][1]\n",
    "\n",
    "    return min_x, min_y, min_index, min_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_refined_homography_outlier_mask(control_pts):\n",
    "    \"\"\"\n",
    "    Computes homography from mapped control points and outlier mask using RANSAC\n",
    "\n",
    "    :param control_pts: List of control points in both query image and world map\n",
    "                        co-ordinates\n",
    "\n",
    "    :returns:\n",
    "        homography_matrix: Computed Homography matrix\n",
    "        outlier_mask: Mask array with flags indicating whether control points inlier or not\n",
    "    \"\"\"\n",
    "\n",
    "    if len(control_pts) < 4:\n",
    "        return None, None\n",
    "\n",
    "    src_points = np.zeros((len(control_pts), 2), dtype=np.float32)\n",
    "    dst_points = np.zeros((len(control_pts), 2), dtype=np.float32)\n",
    "\n",
    "    for i, control_pt in enumerate(control_pts):\n",
    "        src_points[i, 0] = control_pt[0]\n",
    "        src_points[i, 1] = -1 * control_pt[1]\n",
    "        dst_points[i, 0] = control_pt[5]\n",
    "        dst_points[i, 1] = -1 * control_pt[6]\n",
    "\n",
    "    homography_matrix, outlier_mask = cv2.findHomography(src_points, dst_points, cv2.RANSAC, 3)\n",
    "\n",
    "    return homography_matrix, outlier_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reference_homography(bb_start_x, bb_start_y,\n",
    "                                 bb_end_x, bb_end_y,\n",
    "                                 world_map_height, world_map_width,\n",
    "                                 template_height, template_width):\n",
    "    \"\"\"\n",
    "    Computes the homography transform mapping query image onto world map\n",
    "\n",
    "    :param bb_start_x : bounding box left x co-ordinate\n",
    "    :param bb_start_y : bounding box top y co-ordinate\n",
    "    :param bb_end_x : bounding box right x co-ordinate\n",
    "    :param bb_end_y : bounding box bottom x co-ordinate\n",
    "    :param world_map_height: Height of world map\n",
    "    :param world_map_width: Width of world map\n",
    "    :param template_height: Height of template image\n",
    "    :param template_width: Width of template image\n",
    "\n",
    "    :returns:\n",
    "        homography_matrix : Computed transformation matrix\n",
    "    \"\"\"\n",
    "\n",
    "    src_points = np.array([[0, 0],\n",
    "                           [template_width - 1, 0],\n",
    "                           [template_width - 1, template_height - 1],\n",
    "                           [0, template_height - 1]],\n",
    "                          dtype=np.float32)\n",
    "\n",
    "    dst_points = np.array([[bb_start_x, bb_start_y],\n",
    "                           [bb_end_x, bb_start_y],\n",
    "                           [bb_end_x, bb_end_y],\n",
    "                           [bb_start_x, bb_end_y]],\n",
    "                          dtype=np.float32)\n",
    "\n",
    "    # Compute the reference homography using perspective transform function of OpenCV\n",
    "    homography_matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "\n",
    "    return homography_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_control_pts(world_map, query_image, control_pts):\n",
    "    world_map_img_copy = world_map.copy()\n",
    "    query_image_copy = query_image.copy()\n",
    "\n",
    "    colors = create_random_color_list(len(control_pts))\n",
    "\n",
    "    for i, control_pt in enumerate(control_pts):\n",
    "        color = colors[i]\n",
    "        color = tuple([int(x) for x in color])\n",
    "\n",
    "        query_image_copy = cv2.drawMarker(query_image_copy,\n",
    "                                          (control_pt[0], -1 * control_pt[1]), color)\n",
    "\n",
    "        world_map_img_copy = cv2.drawMarker(world_map_img_copy,\n",
    "                                            (int(control_pt[5]), int(-1 * control_pt[6])), color)\n",
    "\n",
    "    return world_map_img_copy, query_image_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_control_pts(control_pts, world_map_contour_processed):\n",
    "    \"\"\"\n",
    "    Refines already detected control points using world map contour matching with\n",
    "    biggest contour in query image\n",
    "    \n",
    "    :param control_pts: control points to be refined\n",
    "    :param world_map_contour_processed: Offsetted world map contour\n",
    "\n",
    "    :returns:\n",
    "        control_pts: Refined control points\n",
    "    \"\"\"\n",
    "\n",
    "    for control_pt in control_pts:\n",
    "        min_x, min_y, min_index, min_distance = find_nearest_point_on_contour(\n",
    "            world_map_contour_processed, control_pt[5],-1 * control_pt[6])\n",
    "\n",
    "        if min_index > 0 and min_distance < REFINEMENT_DISTANCE_THRESHOLD:\n",
    "            control_pt[5] = min_x\n",
    "            control_pt[6] = -1 * (min_y)\n",
    "            control_pt[2] = LONGITUDE_EXTREME_LEFT \\\n",
    "                            + (degree_per_pixel_x * min_x)\n",
    "\n",
    "            control_pt[3] = LATITUDE_EXTREME_TOP \\\n",
    "                            + (degree_per_pixel_y * min_y)\n",
    "\n",
    "    return control_pts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_control_points(world_map_roi_processed, template,\n",
    "                            world_map_roi_processed_offset_x,\n",
    "                            world_map_roi_processed_offset_y,\n",
    "                            world_map_roi_processed_start_x,\n",
    "                            world_map_roi_processed_start_y,\n",
    "                            template_warped_start_x,\n",
    "                            template_warped_start_y,\n",
    "                            degree_per_pixel_x,\n",
    "                            degree_per_pixel_y):\n",
    "    \"\"\"\n",
    "    Detects contours in template image and finds correpondences in processed world map image ROI\n",
    "\n",
    "    :param world_map_roi_processed: Processed world map image ROI\n",
    "    :param template: Template image\n",
    "    :param world_map_roi_processed_offset_x: X Margin for world map ROI w.r.t warped template\n",
    "    :param world_map_roi_processed_offset_y: Y Margin for world map ROI w.r.t warped template\n",
    "    :param world_map_roi_processed_start_x: X co-ordinate of left top corner of world map roi\n",
    "    :param world_map_roi_processed_start_y: Y co-ordinate of left top corner of world map roi\n",
    "    :param template_warped_start_x: X co-ordinate of left top corner of warped template\n",
    "    :param template_warped_start_y: Y co-ordinate of left top corner of warped template\n",
    "    :param degree_per_pixel_x: Degrees per pixel in x direction\n",
    "    :param degree_per_pixel_y: Degrees  per pixel in y direction\n",
    "\n",
    "    :returns:\n",
    "        mapped_control_pts: List of control points in template and corresponding points in\n",
    "                            world map\n",
    "    \"\"\"\n",
    "    # Detect contours in world map roi and template\n",
    "    world_map_roi_contours = detect_contours(world_map_roi_processed)\n",
    "    template_contours = detect_contours(template)\n",
    "\n",
    "    # Find the biggest template contour in terms of area\n",
    "    biggest_template_contour = max(template_contours, key=cv2.contourArea)\n",
    "\n",
    "    template_contour_img = template.copy()\n",
    "    template_contour_img = cv2.drawContours(template_contour_img, [biggest_template_contour],\n",
    "                                            -1, (128, 128, 128), 4)\n",
    "\n",
    "    write_image_to_disk(template_contour_img, \"template_contour_img\")\n",
    "\n",
    "    # Create list of contour points in template for which matches need to be found\n",
    "    contour_pts = []\n",
    "\n",
    "    (bb_cnt_xmin, bb_cnt_ymin, bb_cnt_width, bb_cnt_height) = \\\n",
    "        cv2.boundingRect(biggest_template_contour)\n",
    "\n",
    "    bb_cnt_area = bb_cnt_width * bb_cnt_height\n",
    "    template_area = template.shape[0] * template.shape[1]\n",
    "\n",
    "    area_ratio = bb_cnt_area / template_area\n",
    "\n",
    "    if area_ratio < CONTOUR_RECT_AREA_RATIO_THRESHOLD:\n",
    "        for contour in template_contours:\n",
    "            for contour_pt in contour:\n",
    "                contour_pts.append(contour_pt)\n",
    "\n",
    "    else:\n",
    "        contour_pts = biggest_template_contour\n",
    "\n",
    "    # Initialize parameters for patch matching\n",
    "    length_diagonal_template_img = calculate_diagonal_length(template.shape[1],\n",
    "                                                             template.shape[0])\n",
    "    contour_patch_window = int(length_diagonal_template_img\n",
    "                               / CONTOUR_PATCH_SIZE_FACTOR)\n",
    "\n",
    "    delta_contour_patch_window = contour_patch_window / 2\n",
    "\n",
    "    world_img_patch_window = int(contour_patch_window * WORLD_MAP_PATCH_SIZE_FACTOR)\n",
    "    delta_world_map_patch_window = (world_img_patch_window / 2)\n",
    "\n",
    "    mapped_control_pts = []\n",
    "\n",
    "    for contour_pt in contour_pts:\n",
    "\n",
    "        contour_pt_x = contour_pt[0][0]\n",
    "        contour_pt_y = contour_pt[0][1]\n",
    "\n",
    "        # Create contour patch around contour point\n",
    "        contour_patch_start_y = contour_pt_y - delta_contour_patch_window\n",
    "        contour_patch_end_y = contour_pt_y + delta_contour_patch_window\n",
    "        contour_patch_start_x = contour_pt_x - delta_contour_patch_window\n",
    "        contour_patch_end_x = contour_pt_x + delta_contour_patch_window\n",
    "\n",
    "        contour_patch_start_x, contour_patch_start_y, contour_patch_end_x, contour_patch_end_y = \\\n",
    "            check_bb_boundary(contour_patch_start_x, contour_patch_start_y,\n",
    "                              contour_patch_end_x, contour_patch_end_y,\n",
    "                              template.shape[0], template.shape[1])\n",
    "\n",
    "        contour_patch = template[int(contour_patch_start_y): int(contour_patch_end_y),\n",
    "                        int(contour_patch_start_x): int(contour_patch_end_x)]\n",
    "\n",
    "        # write_image_to_disk(contour_patch, \"contour_patch\")\n",
    "\n",
    "        # Check if contour patch is qualified for matching\n",
    "        contour_patch_non_zero_ratio = calculate_nonzero_ratio(contour_patch)\n",
    "\n",
    "        if contour_patch_non_zero_ratio > CONTOUR_PATCH_NON_ZERO_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        world_map_patch_start_y = contour_pt_y - delta_world_map_patch_window \\\n",
    "                                  + world_map_roi_processed_offset_y\n",
    "        world_map_patch_end_y = contour_pt_y + delta_world_map_patch_window \\\n",
    "                                + world_map_roi_processed_offset_y\n",
    "        world_map_patch_start_x = contour_pt_x - delta_world_map_patch_window \\\n",
    "                                  + world_map_roi_processed_offset_x\n",
    "        world_map_patch_end_x = contour_pt_x + delta_world_map_patch_window \\\n",
    "                                + world_map_roi_processed_offset_x\n",
    "\n",
    "        world_map_patch_start_x, world_map_patch_start_y, world_map_patch_end_x, world_map_patch_end_y = \\\n",
    "            check_bb_boundary(world_map_patch_start_x, world_map_patch_start_y,\n",
    "                              world_map_patch_end_x, world_map_patch_end_y,\n",
    "                              world_map_roi_processed.shape[0], world_map_roi_processed.shape[1])\n",
    "\n",
    "        world_map_patch = world_map_roi_processed[int(world_map_patch_start_y): int(world_map_patch_end_y),\n",
    "                          int(world_map_patch_start_x): int(world_map_patch_end_x)]\n",
    "\n",
    "        # write_image_to_disk(world_map_patch, \"world_map_patch\")\n",
    "\n",
    "        # Check if world map patch is qualified for matching\n",
    "        world_img_patch_non_zero_ratio = calculate_nonzero_ratio(world_map_patch)\n",
    "\n",
    "        if world_img_patch_non_zero_ratio > WORLD_MAP_PATCH_NON_ZERO_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        detection_start_x, detection_start_y, detection_end_x, detection_end_y, detection_val, scale_factor = \\\n",
    "            detect_template(contour_patch, world_map_patch, 1.0, 1.0, 1)\n",
    "\n",
    "        if detection_val > 0:\n",
    "            # Compute centroid in detected world map patch\n",
    "            ratio_x, ratio_y = \\\n",
    "                calculate_distance_ratios(contour_patch_start_x, contour_patch_start_y,\n",
    "                                          contour_patch_end_x, contour_patch_end_y,\n",
    "                                          contour_pt_x, contour_pt_y)\n",
    "\n",
    "            world_map_patch_centroid_x = ((ratio_x * detection_end_x) + detection_start_x) / (ratio_x + 1)\n",
    "            world_map_patch_centroid_y = ((ratio_y * detection_end_y) + detection_start_y) / (ratio_y + 1)\n",
    "\n",
    "            # Transform centroid to world map co-ordinates\n",
    "            centroid_world_map_detection_x = world_map_patch_centroid_x \\\n",
    "                                             + world_map_patch_start_x \\\n",
    "                                             + world_map_roi_processed_start_x\n",
    "            centroid_world_map_detection_y = world_map_patch_centroid_y \\\n",
    "                                             + world_map_patch_start_y \\\n",
    "                                             + world_map_roi_processed_start_y\n",
    "\n",
    "            # Calculate latitude and longitude co-ordinates\n",
    "            centroid_world_map_detection_x_long = LONGITUDE_EXTREME_LEFT \\\n",
    "                                                  + (degree_per_pixel_x * centroid_world_map_detection_x)\n",
    "            centroid_world_map_detection_y_lat = LATITUDE_EXTREME_TOP \\\n",
    "                                                 + (degree_per_pixel_y * centroid_world_map_detection_y)\n",
    "\n",
    "            mapped_control_pts.append([contour_pt_x, -1 * contour_pt_y,\n",
    "                                       centroid_world_map_detection_x_long,\n",
    "                                       centroid_world_map_detection_y_lat,\n",
    "                                       detection_val, centroid_world_map_detection_x,\n",
    "                                       -1 * centroid_world_map_detection_y])\n",
    "\n",
    "    return mapped_control_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_homography(query_img, world_map, homography_matrix):\n",
    "    \"\"\"\n",
    "    Applies estimated homography on template image and returns modified world map\n",
    "\n",
    "    :param: query_img: Image to be processed\n",
    "    :param: world_map: World map image\n",
    "    :param: homography_matrix: Homography matrix to be used\n",
    "\n",
    "    :returns:\n",
    "        modified_world_map: Modified world map image\n",
    "    \"\"\"\n",
    "\n",
    "    world_map_height = world_map.shape[0]\n",
    "    world_map_width = world_map.shape[1]\n",
    "\n",
    "    warped_query_img = cv2.warpPerspective(query_img, homography_matrix,\n",
    "                                           (world_map_width, world_map_height))\n",
    "\n",
    "    modified_world_map = world_map.copy()\n",
    "\n",
    "    for y in range(0, world_map_height):\n",
    "        for x in range(0, world_map_width):\n",
    "            if warped_query_img[y][x][0] != 0:\n",
    "                modified_world_map[y][x][0] = warped_query_img[y][x][0]\n",
    "                modified_world_map[y][x][1] = warped_query_img[y][x][1]\n",
    "                modified_world_map[y][x][2] = warped_query_img[y][x][2]\n",
    "\n",
    "    return modified_world_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare_homography_matrices(reference_homography, refined_homography,\n",
    "                                control_pts, outlier_mask,\n",
    "                                template, world_map):\n",
    "    \"\"\"\n",
    "    Compares the estimated homographies and selects the better homography\n",
    "\n",
    "    :param: reference_homography: Estimated reference homography\n",
    "    :param: refined_homography: Estimated refined homography\n",
    "    :param: control_pts: Control points used to compute refined homography\n",
    "    :param: world_map: World map image\n",
    "\n",
    "    :returns:\n",
    "        final_homography: Selected homography matrix\n",
    "    \"\"\"\n",
    "\n",
    "    world_map_height = world_map.shape[0]\n",
    "    world_map_width = world_map.shape[1]\n",
    "\n",
    "    warped_template_reference_homography = cv2.warpPerspective(template, reference_homography,\n",
    "                                                               (world_map_width, world_map_height))\n",
    "\n",
    "    warped_template_refined_homography = cv2.warpPerspective(template, refined_homography,\n",
    "                                                             (world_map_width, world_map_height))\n",
    "\n",
    "    warped_template_reference_mask = np.zeros((world_map_height, world_map_width),\n",
    "                                              dtype=np.uint8)\n",
    "\n",
    "    warped_template_refined_mask = np.zeros((world_map_height, world_map_width),\n",
    "                                            dtype=np.uint8)\n",
    "\n",
    "    for y in range(0, world_map_height):\n",
    "        for x in range(0, world_map_width):\n",
    "\n",
    "            if warped_template_reference_homography[y][x] != 0:\n",
    "                warped_template_reference_mask[y][x] = 255\n",
    "\n",
    "            if warped_template_refined_homography[y][x] != 0:\n",
    "                warped_template_refined_mask[y][x] = 255\n",
    "\n",
    "    iou = calculate_iou_binary_images(warped_template_reference_mask,\n",
    "                                      warped_template_refined_mask)\n",
    "\n",
    "    if iou < IOU_THRESHOLD_HOMOGRAPHY:\n",
    "        return reference_homography, 0\n",
    "    else:\n",
    "        return refined_homography, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register(query_img_filepath, region_mask_filepath):\n",
    "    \"\"\"\n",
    "    Registers query image onto world map and maps the region mask onto world map\n",
    "\n",
    "    :param: query_img_filepath: Path to the query image\n",
    "    :param: region_img_filepath: Path to the region image\n",
    "\n",
    "    :retuns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Read the image to be registered\n",
    "    query_img = cv2.imread(str(query_img_filepath))\n",
    "\n",
    "    # Read the region image\n",
    "    region_img = cv2.imread(str(region_mask_filepath))\n",
    "\n",
    "    # Create species region mask\n",
    "    region_mask_img = create_region_mask(region_img)\n",
    "\n",
    "    # Fill the species region in the image to be registered\n",
    "    query_img_filled = fill_mask_pixels(query_img, region_mask_img)\n",
    "\n",
    "    # Create template image\n",
    "    query_img_processed = preprocess(query_img_filled, 5)\n",
    "    write_image_to_disk(query_img_processed, \"query_img_processed\")\n",
    "\n",
    "    template = homogenize(query_img_processed)\n",
    "    write_image_to_disk(template, \"template\")\n",
    "\n",
    "    # Load world map image\n",
    "    world_map_img = cv2.imread(os.path.join(WORLD_MAP_IMAGE_PATH, WORLD_MAP_IMAGE_NAME))\n",
    "\n",
    "    # Homogenized world image\n",
    "    world_map_processed = homogenize(world_map_img)\n",
    "    write_image_to_disk(world_map_processed, \"world_map_processed\")\n",
    "\n",
    "    # Find template in world map\n",
    "    detection_start_x, detection_start_y, detection_end_x, detection_end_y, detection_val, scale_factor = \\\n",
    "        detect_template(template, world_map_processed, 0.2, 2.0, 40)\n",
    "\n",
    "    # Resize world map to the scale at which template was found\n",
    "    # world_map_processed_resized = \\\n",
    "    #    imutils.resize(world_map_processed, width=int(world_map_processed.shape[1] / scale_factor))\n",
    "\n",
    "    # detection_start_x *= scale_factor\n",
    "    # detection_start_y *= scale_factor\n",
    "    # detection_end_x *= scale_factor\n",
    "    # detection_end_y *= scale_factor\n",
    "\n",
    "    world_map_img_height = world_map_img.shape[0]\n",
    "    world_map_img_width = world_map_img.shape[1]\n",
    "\n",
    "    # Compute reference homography\n",
    "    reference_homography = compute_reference_homography(detection_start_x, detection_start_y,\n",
    "                                                        detection_end_x, detection_end_y,\n",
    "                                                        world_map_processed.shape[0],\n",
    "                                                        world_map_processed.shape[1],\n",
    "                                                        template.shape[0], template.shape[1])\n",
    "\n",
    "    reference_image = apply_homography(query_img, world_map_img, reference_homography)\n",
    "    write_image_to_disk(reference_image, \"reference_image\")\n",
    "\n",
    "    warped_template_image = cv2.warpPerspective(template, reference_homography,\n",
    "                                                (world_map_img_width, world_map_img_height))\n",
    "    warped_query_image = cv2.warpPerspective(query_img, reference_homography,\n",
    "                                             (world_map_img_width, world_map_img_height))\n",
    "\n",
    "    # Create warped template to be used for computing refined homography\n",
    "    warped_template = warped_template_image[detection_start_y: detection_end_y,\n",
    "                      detection_start_x: detection_end_x]\n",
    "\n",
    "    warped_query = warped_query_image[detection_start_y: detection_end_y,\n",
    "                   detection_start_x: detection_end_x]\n",
    "\n",
    "    # Create world map roi image to be used for computing refined homography\n",
    "    world_map_roi_margin_x = 300\n",
    "    world_map_roi_margin_y = 0  # 0.05 * world_map_processed.shape[0]\n",
    "\n",
    "    world_map_roi_start_x = detection_start_x - world_map_roi_margin_x\n",
    "    world_map_roi_end_x = detection_end_x + world_map_roi_margin_x\n",
    "    world_map_roi_start_y = detection_start_y - world_map_roi_margin_y\n",
    "    world_map_roi_end_y = detection_end_y + world_map_roi_margin_y\n",
    "\n",
    "    world_map_roi_start_x, world_map_roi_start_y, world_map_roi_end_x, world_map_roi_end_y = \\\n",
    "        check_bb_boundary(world_map_roi_start_x, world_map_roi_start_y,\n",
    "                          world_map_roi_end_x, world_map_roi_end_y,\n",
    "                          world_map_processed.shape[0],\n",
    "                          world_map_processed.shape[1])\n",
    "\n",
    "    world_map_img_offset_start_x = detection_start_x - world_map_roi_start_x\n",
    "    world_map_img_offset_start_y = detection_start_y - world_map_roi_start_y\n",
    "\n",
    "    world_map_roi_processed = \\\n",
    "        world_map_processed[int(world_map_roi_start_y): int(world_map_roi_end_y),\n",
    "        int(world_map_roi_start_x): int(world_map_roi_end_x)]\n",
    "\n",
    "    write_image_to_disk(world_map_roi_processed, \"world_map_roi_processed\")\n",
    "\n",
    "    # Initialization of degree per pixel values\n",
    "    degree_per_pixel_x = (LONGITUDE_EXTREME_RIGHT - LONGITUDE_EXTREME_LEFT) \\\n",
    "                         / world_map_processed.shape[1]\n",
    "\n",
    "    degree_per_pixel_y = (LATITUDE_EXTREME_BOTTOM - LATITUDE_EXTREME_TOP) \\\n",
    "                         / world_map_processed.shape[0]\n",
    "\n",
    "    # Calculate control point pairs\n",
    "    control_pts = estimate_control_points(world_map_roi_processed, warped_template,\n",
    "                                          world_map_img_offset_start_x,\n",
    "                                          world_map_img_offset_start_y,\n",
    "                                          world_map_roi_start_x,\n",
    "                                          world_map_roi_start_y,\n",
    "                                          detection_start_x,\n",
    "                                          detection_start_y,\n",
    "                                          degree_per_pixel_x,\n",
    "                                          degree_per_pixel_y)\n",
    "\n",
    "    world_map_control_pts, query_control_pts = annotate_control_pts(world_map_img, warped_query, control_pts)\n",
    "    write_image_to_disk(world_map_control_pts, \"world_map_control_pts\")\n",
    "    write_image_to_disk(query_control_pts, \"query_control_pts\")\n",
    "\n",
    "    # Compute refined homography\n",
    "    refined_homography, outlier_mask = compute_refined_homography_outlier_mask(control_pts)\n",
    "\n",
    "    refined_image = apply_homography(warped_query, world_map_img, refined_homography)\n",
    "    write_image_to_disk(refined_image, \"refined_image\")\n",
    "\n",
    "    # Comparison of reference homography with refined homography for selection of final homography\n",
    "    final_homography, selected_index = compare_homography_matrices(reference_homography,\n",
    "                                                   refined_homography,\n",
    "                                                   control_pts, outlier_mask,\n",
    "                                                   template, world_map_img)\n",
    "\n",
    "    # Apply selected homography on the query image\n",
    "    if selected_index == 0:\n",
    "        final_image = apply_homography(query_img, world_map_img, final_homography)\n",
    "    else:\n",
    "        final_image = apply_homography(warped_query, world_map_img, final_homography)\n",
    "\n",
    "    write_image_to_disk(final_image, \"final_image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping over all images and executing the image registration pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to maps : C:\\Users\\ati11038\\Documents\\workspace\\data\\half_earth\\extracted_samples\\extracted_maps\n",
      "Path to masks : C:\\Users\\ati11038\\Documents\\workspace\\data\\half_earth\\extracted_samples\\extracted_masks\n",
      "Number of scanned images to process: 1587\n",
      "Processing 7lomys_mirae & 7lomys_mirae_mask\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# Initialization of world map and degree per pixel values\n",
    "world_map_img = cv2.imread(os.path.join(WORLD_MAP_IMAGE_PATH,\n",
    "                                        WORLD_MAP_IMAGE_NAME))\n",
    "\n",
    "\n",
    "\n",
    "# Create list of image files to register and list of species region masks\n",
    "path_maps = Path(IMAGES_TO_REGISTER_FOLDER)\n",
    "print(\"Path to maps : \" + str(path_maps))\n",
    "\n",
    "path_masks = Path(IMAGES_TO_REGISTER_SPECIES_MASKS_FOLDER)\n",
    "print(\"Path to masks : \" + str(path_masks))\n",
    "\n",
    "# Create list of scanned image and species mask filepaths  \n",
    "scanned_images_filepaths = [file_path for file_path in path_maps.glob('**/*.jpg')]\n",
    "species_masks_filepaths = [file_path for file_path in path_masks.glob('**/*.jpg')]\n",
    "\n",
    "# Sort the image filenames in alphabetical order\n",
    "scanned_images_filepaths = sorted(scanned_images_filepaths)\n",
    "species_masks_filepaths = sorted(species_masks_filepaths)\n",
    "\n",
    "# Check if the number of images to register is same as number of species mask images\n",
    "assert len(scanned_images_filepaths) == len(species_masks_filepaths)\n",
    "\n",
    "print(\"Number of scanned images to process: \" + str(len(scanned_images_filepaths)))\n",
    "\n",
    "# Loop over all the images and species masks and execute the pipeline\n",
    "for index in range(0, len(scanned_images_filepaths)):\n",
    "    \n",
    "    scanned_image_filepath = scanned_images_filepaths[index]\n",
    "    species_mask_filepath = species_masks_filepaths[index]\n",
    "    \n",
    "    # Extract the filenames of scanned image and species mask\n",
    "    scanned_image_filepath_split_list = str(scanned_image_filepath).split(\"\\\\\")\n",
    "    scanned_image_filename_prefix = scanned_image_filepath_split_list[-1].split(\".\")[0]\n",
    "  \n",
    "    species_mask_filepath_split_list = str(species_mask_filepath).split(\"\\\\\")\n",
    "    species_mask_filename_prefix = species_mask_filepath_split_list[-1].split(\".\")[0]\n",
    "    \n",
    "    print(\"Processing \" + scanned_image_filename_prefix + \" & \" + species_mask_filename_prefix)\n",
    "\n",
    "    # Update current image prefix\n",
    "    current_image_prefix = scanned_image_filename_prefix\n",
    "    \n",
    "    register(scanned_images_filepaths[index], species_masks_filepaths[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
